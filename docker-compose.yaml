version: "3.9"
services:
  prediction_api:
    build: .
    container_name: "inference_container"
    ports:
      - "8000:8000"
  
  prediction_api:
    image: inference